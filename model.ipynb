{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"concave points_worst\", \"perimeter_worst\", \"concave points_mean\",\n",
    "    \"radius_worst\", \"perimeter_mean\", \"area_worst\",\n",
    "    \"radius_mean\", \"area_mean\", \"concavity_mean\", \"concavity_worst\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[selected_features]  # Independent variables\n",
    "Y = df[\"diagnosis\"]  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     concave points_worst  perimeter_worst  concave points_mean  radius_worst  \\\n",
       " 0                  0.2654           184.60              0.14710        25.380   \n",
       " 1                  0.1860           158.80              0.07017        24.990   \n",
       " 2                  0.2430           152.50              0.12790        23.570   \n",
       " 3                  0.2575            98.87              0.10520        14.910   \n",
       " 4                  0.1625           152.20              0.10430        22.540   \n",
       " ..                    ...              ...                  ...           ...   \n",
       " 564                0.2216           166.10              0.13890        25.450   \n",
       " 565                0.1628           155.00              0.09791        23.690   \n",
       " 566                0.1418           126.70              0.05302        18.980   \n",
       " 567                0.2650           184.60              0.15200        25.740   \n",
       " 568                0.0000            59.16              0.00000         9.456   \n",
       " \n",
       "      perimeter_mean  area_worst  radius_mean  area_mean  concavity_mean  \\\n",
       " 0            122.80      2019.0        17.99     1001.0         0.30010   \n",
       " 1            132.90      1956.0        20.57     1326.0         0.08690   \n",
       " 2            130.00      1709.0        19.69     1203.0         0.19740   \n",
       " 3             77.58       567.7        11.42      386.1         0.24140   \n",
       " 4            135.10      1575.0        20.29     1297.0         0.19800   \n",
       " ..              ...         ...          ...        ...             ...   \n",
       " 564          142.00      2027.0        21.56     1479.0         0.24390   \n",
       " 565          131.20      1731.0        20.13     1261.0         0.14400   \n",
       " 566          108.30      1124.0        16.60      858.1         0.09251   \n",
       " 567          140.10      1821.0        20.60     1265.0         0.35140   \n",
       " 568           47.92       268.6         7.76      181.0         0.00000   \n",
       " \n",
       "      concavity_worst  \n",
       " 0             0.7119  \n",
       " 1             0.2416  \n",
       " 2             0.4504  \n",
       " 3             0.6869  \n",
       " 4             0.4000  \n",
       " ..               ...  \n",
       " 564           0.4107  \n",
       " 565           0.3215  \n",
       " 566           0.3403  \n",
       " 567           0.9387  \n",
       " 568           0.0000  \n",
       " \n",
       " [569 rows x 10 columns],\n",
       " 0      M\n",
       " 1      M\n",
       " 2      M\n",
       " 3      M\n",
       " 4      M\n",
       "       ..\n",
       " 564    M\n",
       " 565    M\n",
       " 566    M\n",
       " 567    M\n",
       " 568    B\n",
       " Name: diagnosis, Length: 569, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.9737\n",
      "Precision: 0.9545\n",
      "Recall: 0.9767\n",
      "F1-score: 0.9655\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9561\n",
      "Precision: 0.9524\n",
      "Recall: 0.9302\n",
      "F1-score: 0.9412\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.9211\n",
      "Precision: 0.9048\n",
      "Recall: 0.8837\n",
      "F1-score: 0.8941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(Y_test, y_pred),\n",
    "        \"Precision\": precision_score(Y_test, y_pred),\n",
    "        \"Recall\": recall_score(Y_test, y_pred),\n",
    "        \"F1-score\": f1_score(Y_test, y_pred),\n",
    "        \n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Accuracy': 0.9736842105263158,\n",
       "  'Precision': 0.9545454545454546,\n",
       "  'Recall': 0.9767441860465116,\n",
       "  'F1-score': 0.9655172413793104},\n",
       " 'Random Forest': {'Accuracy': 0.956140350877193,\n",
       "  'Precision': 0.9523809523809523,\n",
       "  'Recall': 0.9302325581395349,\n",
       "  'F1-score': 0.9411764705882353},\n",
       " 'Decision Tree': {'Accuracy': 0.9210526315789473,\n",
       "  'Precision': 0.9047619047619048,\n",
       "  'Recall': 0.8837209302325582,\n",
       "  'F1-score': 0.8941176470588236}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = dict(sorted(results.items(), key=lambda item: item[1][\"Accuracy\"], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Accuracy': 0.9736842105263158,\n",
       "  'Precision': 0.9545454545454546,\n",
       "  'Recall': 0.9767441860465116,\n",
       "  'F1-score': 0.9655172413793104},\n",
       " 'Random Forest': {'Accuracy': 0.956140350877193,\n",
       "  'Precision': 0.9523809523809523,\n",
       "  'Recall': 0.9302325581395349,\n",
       "  'F1-score': 0.9411764705882353},\n",
       " 'Decision Tree': {'Accuracy': 0.9210526315789473,\n",
       "  'Precision': 0.9047619047619048,\n",
       "  'Recall': 0.8837209302325582,\n",
       "  'F1-score': 0.8941176470588236}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "[0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1\n",
      " 0 0 1]\n",
      "Actual values:\n",
      "[0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1\n",
      " 0 0 1]\n",
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instantiate and train the Logistic Regression model\n",
    "logistic_reg = LogisticRegression(random_state=0)\n",
    "logistic_reg.fit(X_test, Y_test)\n",
    "\n",
    "# Prediction using Logistic Regression\n",
    "pred_logistic = logistic_reg.predict(X_test)\n",
    "\n",
    "print('Predicted values:')\n",
    "print(pred_logistic)\n",
    "print('Actual values:')\n",
    "print(Y_test)\n",
    "\n",
    "accuracy_logistic = accuracy_score(Y_test, pred_logistic)\n",
    "print('Accuracy:', accuracy_logistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
